{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37a73211",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "from matplotlib import pyplot as plt \n",
    "from datasets import load_dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c556543f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-1): 2 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The same as https://huggingface.co/google/bert_uncased_L-2_H-128_A-2\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"prajjwal1/bert-tiny\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"prajjwal1/bert-tiny\")\n",
    "\n",
    "trained = torch.load('SST-2-BERT-tiny.bin', map_location=torch.device('cpu'))\n",
    "model.load_state_dict(trained , strict=True)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea8b379b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_parquet(\"SST-2-val.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fbf1654b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it 's a charming and often affecting journey .</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unflinchingly bleak and desperate</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allows us to hope that nolan is poised to emba...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the acting , costumes , music , cinematography...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it 's slow -- very , very slow .</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>has all the depth of a wading pool .</td>\n",
       "      <td>0</td>\n",
       "      <td>867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>a movie with a real anarchic flair .</td>\n",
       "      <td>1</td>\n",
       "      <td>868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>a subject like this should inspire reaction in...</td>\n",
       "      <td>0</td>\n",
       "      <td>869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>... is an arthritic attempt at directing by ca...</td>\n",
       "      <td>0</td>\n",
       "      <td>870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>looking aristocratic , luminous yet careworn i...</td>\n",
       "      <td>1</td>\n",
       "      <td>871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>872 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence  label  idx\n",
       "0      it 's a charming and often affecting journey .       1    0\n",
       "1                   unflinchingly bleak and desperate       0    1\n",
       "2    allows us to hope that nolan is poised to emba...      1    2\n",
       "3    the acting , costumes , music , cinematography...      1    3\n",
       "4                    it 's slow -- very , very slow .       0    4\n",
       "..                                                 ...    ...  ...\n",
       "867              has all the depth of a wading pool .       0  867\n",
       "868              a movie with a real anarchic flair .       1  868\n",
       "869  a subject like this should inspire reaction in...      0  869\n",
       "870  ... is an arthritic attempt at directing by ca...      0  870\n",
       "871  looking aristocratic , luminous yet careworn i...      1  871\n",
       "\n",
       "[872 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66148ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = []\n",
    "\n",
    "for ind in dataset.index:\n",
    "    \n",
    "    text = \"[CLS] \" + dataset['sentence'][ind] + \" [SEP]\"\n",
    "\n",
    "    tokenized = tokenizer(text)\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        \n",
    "    x = model.bert.embeddings(tokens_tensor, torch.tensor([[1] * len(tokenized_text)]))\n",
    "    \n",
    "    shapes.append(x.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bdb93aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([872., 836., 721., 589., 436., 282., 171.,  93.,  32.,  12.]),\n",
       " array([ 4. ,  9.1, 14.2, 19.3, 24.4, 29.5, 34.6, 39.7, 44.8, 49.9, 55. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(shapes, cumulative=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d2ff36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = []\n",
    "\n",
    "distances_small = []\n",
    "\n",
    "for ind in dataset.index:\n",
    "    \n",
    "    text = \"[CLS] \" + dataset['sentence'][ind] + \" [SEP]\"\n",
    "\n",
    "    tokenized = tokenizer(text)\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        \n",
    "    res = model(tokens_tensor, torch.tensor([[1] * len(tokenized_text)]))\n",
    "    distances.append(abs(res.logits[0][0].item() - res.logits[0][1].item()))\n",
    "    \n",
    "    if abs(res.logits[0][0].item() - res.logits[0][1].item()) < 0.5:\n",
    "        distances_small.append(ind)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d66da3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9426605504587156"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - len(distances_small) / len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d854aa8a",
   "metadata": {},
   "source": [
    "TODO: lanciare FHE BERT con queste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de1f6f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sono 50\n",
      "24 tokens\n",
      "36 tokens\n",
      "38 tokens\n",
      "16 tokens\n",
      "12 tokens\n",
      "35 tokens\n",
      "22 tokens\n",
      "36 tokens\n",
      "15 tokens\n",
      "30 tokens\n",
      "28 tokens\n",
      "18 tokens\n",
      "36 tokens\n",
      "37 tokens\n",
      "18 tokens\n",
      "13 tokens\n",
      "50 tokens\n",
      "39 tokens\n",
      "39 tokens\n",
      "38 tokens\n",
      "14 tokens\n",
      "23 tokens\n",
      "2 tokens\n",
      "33 tokens\n",
      "13 tokens\n",
      "12 tokens\n",
      "25 tokens\n",
      "23 tokens\n",
      "24 tokens\n",
      "40 tokens\n",
      "26 tokens\n",
      "35 tokens\n",
      "38 tokens\n",
      "33 tokens\n",
      "26 tokens\n",
      "28 tokens\n",
      "11 tokens\n",
      "34 tokens\n",
      "16 tokens\n",
      "42 tokens\n",
      "30 tokens\n",
      "15 tokens\n",
      "38 tokens\n",
      "28 tokens\n",
      "23 tokens\n",
      "33 tokens\n",
      "15 tokens\n",
      "25 tokens\n",
      "39 tokens\n",
      "9 tokens\n"
     ]
    }
   ],
   "source": [
    "print(\"Sono {}\".format(len(distances_small)))\n",
    "for el in distances_small:\n",
    "    print(\"{} tokens\".format(len(tokenizer.tokenize(dataset['sentence'][el]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a80d2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logits(text):\n",
    "    text = \"[CLS] \" + dataset['sentence'][distances_small[1]] + \" [SEP]\"\n",
    "\n",
    "    tokenized = tokenizer(text)\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    return model(tokens_tensor, torch.tensor([[1] * len(tokenized_text)])).logits[0].detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f914578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: we root for ( clara and paul ) , even like them , though perhaps it 's an emotion closer to pity . \n",
      "Logits: tensor([ 0.1886, -0.1056])\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentence: {}\\nLogits: {}\".format(dataset['sentence'][distances_small[0]], get_logits(dataset['sentence'][distances_small[0]])))\n",
    "#Correct con precomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d141382a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \"... designed to provide a mix of smiles and tears , `` crossroads '' instead provokes a handful of unintentional howlers and numerous yawns . \"\n",
      "Logits: tensor([ 0.1886, -0.1056])\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentence: \\\"{}\\\"\\nLogits: {}\".format(dataset['sentence'][distances_small[1]], get_logits(dataset['sentence'][distances_small[1]])))\n",
    "#Correct con precomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "653754f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \"( w ) hile long on amiable monkeys and worthy environmentalism , jane goodall 's wild chimpanzees is short on the thrills the oversize medium demands . \"\n",
      "Logits: tensor([ 0.1886, -0.1056])\n"
     ]
    }
   ],
   "source": [
    "idx = 2\n",
    "print(\"Sentence: \\\"{}\\\"\\nLogits: {}\".format(dataset['sentence'][distances_small[idx]], get_logits(dataset['sentence'][distances_small[idx]])))\n",
    "#Correct con precomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "debf953d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: it offers little beyond the momentary joys of pretty and weightless intellectual entertainment . \n",
      "Logits: tensor([ 0.1886, -0.1056])\n"
     ]
    }
   ],
   "source": [
    "idx = 3\n",
    "print(\"Sentence: {}\\nLogits: {}\".format(dataset['sentence'][distances_small[idx]], get_logits(dataset['sentence'][distances_small[idx]])))\n",
    "#Correct con precomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6f1a34e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: manages to be both repulsively sadistic and mundane . \n",
      "Logits: tensor([ 0.1886, -0.1056])\n"
     ]
    }
   ],
   "source": [
    "idx = 4\n",
    "print(\"Sentence: {}\\nLogits: {}\".format(dataset['sentence'][distances_small[idx]], get_logits(dataset['sentence'][distances_small[idx]])))\n",
    "#Wrong con precomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f1d60812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \"it 's just disappointingly superficial -- a movie that has all the elements necessary to be a fascinating , involving character study , but never does more than scratch the surface . \"\n",
      "Logits: tensor([ 0.1886, -0.1056])\n"
     ]
    }
   ],
   "source": [
    "idx = 5\n",
    "print(\"Sentence: \\\"{}\\\"\\nLogits: {}\".format(dataset['sentence'][distances_small[idx]], get_logits(dataset['sentence'][distances_small[idx]])))\n",
    "#OVERFLOW (1/x a 180000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "865b77a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \"it 's one pussy-ass world when even killer-thrillers revolve around group therapy sessions . \"\n",
      "Logits: tensor([ 0.1886, -0.1056])\n"
     ]
    }
   ],
   "source": [
    "idx = 6\n",
    "print(\"Sentence: \\\"{}\\\"\\nLogits: {}\".format(dataset['sentence'][distances_small[idx]], get_logits(dataset['sentence'][distances_small[idx]])))\n",
    "#Correct con precomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "00ca8f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \"fresnadillo 's dark and jolting images have a way of plying into your subconscious like the nightmare you had a week ago that wo n't go away . \"\n",
      "Logits: tensor([ 0.1886, -0.1056])\n"
     ]
    }
   ],
   "source": [
    "idx = 7\n",
    "print(\"Sentence: \\\"{}\\\"\\nLogits: {}\".format(dataset['sentence'][distances_small[idx]], get_logits(dataset['sentence'][distances_small[idx]])))\n",
    "#Correct con precomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b6476b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \"you wo n't like roger , but you will quickly recognize him . \"\n",
      "Logits: tensor([ 0.1886, -0.1056])\n"
     ]
    }
   ],
   "source": [
    "idx = 8\n",
    "print(\"Sentence: \\\"{}\\\"\\nLogits: {}\".format(dataset['sentence'][distances_small[idx]], get_logits(dataset['sentence'][distances_small[idx]])))\n",
    "#Correct con precomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2be216a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \"byler reveals his characters in a way that intrigues and even fascinates us , and he never reduces the situation to simple melodrama . \"\n",
      "Logits: tensor([ 0.1886, -0.1056])\n"
     ]
    }
   ],
   "source": [
    "idx = 9\n",
    "print(\"Sentence: \\\"{}\\\"\\nLogits: {}\".format(dataset['sentence'][distances_small[idx]], get_logits(dataset['sentence'][distances_small[idx]])))\n",
    "#Correct con precomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "68181af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \"no sophomore slump for director sam mendes , who segues from oscar winner to oscar-winning potential with a smooth sleight of hand . \"\n",
      "Logits: tensor([ 0.1886, -0.1056])\n"
     ]
    }
   ],
   "source": [
    "idx = 10\n",
    "print(\"Sentence: \\\"{}\\\"\\nLogits: {}\".format(dataset['sentence'][distances_small[idx]], get_logits(dataset['sentence'][distances_small[idx]])))\n",
    "#Correct con precomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a78dacf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \"comes ... uncomfortably close to coasting in the treads of the bicycle thief . \"\n",
      "Logits: tensor([ 0.1886, -0.1056])\n"
     ]
    }
   ],
   "source": [
    "idx = 11\n",
    "print(\"Sentence: \\\"{}\\\"\\nLogits: {}\".format(dataset['sentence'][distances_small[idx]], get_logits(dataset['sentence'][distances_small[idx]])))\n",
    "#Correct con precomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "21f99af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \"( lawrence bounces ) all over the stage , dancing , running , sweating , mopping his face and generally displaying the wacky talent that brought him fame in the first place . \"\n",
      "Logits: tensor([ 0.1886, -0.1056])\n"
     ]
    }
   ],
   "source": [
    "idx = 12\n",
    "print(\"Sentence: \\\"{}\\\"\\nLogits: {}\".format(dataset['sentence'][distances_small[idx]], get_logits(dataset['sentence'][distances_small[idx]])))\n",
    "#Sbagliato con precomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fa60c628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \"in the end , we are left with something like two ships passing in the night rather than any insights into gay love , chinese society or the price one pays for being dishonest . \"\n",
      "Logits: tensor([ 0.1886, -0.1056])\n"
     ]
    }
   ],
   "source": [
    "idx = 13\n",
    "print(\"Sentence: \\\"{}\\\"\\nLogits: {}\".format(dataset['sentence'][distances_small[idx]], get_logits(dataset['sentence'][distances_small[idx]])))\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b9cc08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
